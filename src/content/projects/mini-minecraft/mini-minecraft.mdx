---
title: Mini Minecraft
blurb: Voxel-based OpenGL game engine made in a team of three. I implemented chunking, efficient rendering/face culling, block texturing, day/night sky system, flood fill lighting, and GUI/fonts.
duration:
  date: 2023-12-11
  length: 2 months
cover:
  img: ./mini-minecraft.png
  alt: The sun is rising on a hill. Trees with colored lights are in the distance. Clouds are in the sky. The player has glowstone selected in their hotbar.
tags:
  - C++
  - OpenGL
  - Qt
  - Photoshop
role:
  - programming
  - assets
  - UI
teamSize: 3
order: 1
published: true
slug: mini-minecraft
---

import { Vimeo } from "@astro-community/astro-embed-vimeo";
import Link from "@/components/link.astro";
import Img from "@/components/img.astro";

For the final project of our computer graphics class, I worked in a team of three to write a 3D voxel game engine (mostly) from scratch. While we all did parts of the programming, I focused mainly on rendering, GPU programming, and GUI. I'm especially proud of the UI system, which came together very last minute but turned out really well.

Throughout the development process, we were clearly influenced by the way Minecraft approached its game design. However, as someone who grew up playing it, I took this opportunity to change some things I've always wished looked a bit different.

Let's first take a look at this snazzy showcase reel I made (\<3 minutes).

<Vimeo id="893391293" />

It does a nice job of showcasing all of our engine's features and credits who worked on what. To put the video in text form, I implemented the following features:

- Chunking
- Efficient chunk rendering and face culling
- Block texturing and animations
- Distance fog
- Day/night cycle and sky system (sun, moon, clouds, stars)
- Flood fill lighting
- GUI, inventory, and text rendering

I want to talk a bit about each, how I approached them, some technical details, and issues that I faced. Let's begin!

> I can't publicly share any code from this project, so anything I write here are just examples. Please contact me if you would like to see the code.

## Chunking

Just like Minecraft, we group the world terrain into 16x16x256 collections of blocks. That's 16 blocks in the x- and z-directions, and 256 blocks in the y-direction (height).

Actually, this chunk data structure is simply a 1D array that stores the block type at the given index. We use helper functions that convert from a (x, y, z) coordinate to this index, and back. 

```cpp
enum Block {
  EMPTY, STONE, DIRT, OAK_LOG /* ...and many more */
};

// we'll be adding more stuff to this class for later features.
class Chunk
{
private:
  std::array<Block, 16 * 16 * 256> blocks;
};
```

> Why not a multidimensional array? While convenient, the arrays would take up more memory. When we have hundreds of these chunks, this becomes important.

A `Block` is just an enum that declares all the possible block types in our game. This includes `STONE`, `DIRT`, and `OAK_LOG`, but also the `EMPTY` block type, which simply represents air, or the absence of a block. This makes it easy to implement "breaking" a block; we're simply placing an `EMPTY` block!

Our chunks are stored in the `Terrain` class. They also live on the heap. For easy access, we map a chunk's lower-left xz-coordinate (in world space) to a pointer to the chunk. Conceptually, our terrain should "own" these chunks, so we're using `std::unique_ptr`s.

```cpp
class Terrain
{
private:
  std::unordered_map<glm::ivec2, std::unique_ptr<Chunk>> chunks;

public:
  void render_terrain();
};
```

> The `glm` namespace is from the <Link href="https://github.com/g-truc/glm" newTab>GLM library</Link>, which implements vector and matrix types in an OpenGL-friendly manner.

What does `render_terrain()` do? This brings us to...

## Efficient rendering, face culling

...drawing the actual blocks. You see, chunking our terrain has a number of benefits. For instance, my teammate implemented multithreading based on my chunks, which are easier to reason about than individual blocks. We then render the terrain, one chunk at a time.

A block has six faces. Each face has two triangles. If we rendered all six faces for every non-`EMPTY` block in a chunk, every single frame, our GPU would catch on fire and be very sad. There's no point in rendering faces that are covered by another non-`EMPTY` block, because the player never sees it anyway.

<Img src={import("./face-culling.png")} alt="Two blocks are right next to each other. The face in between does not need to be rendered." />

Instead, for each chunk, we iterate over every block in the chunk. For each non-`EMPTY` block, we check its six neighbors, and only render that side's face if that neighbor is not `EMPTY`. 

> I did not implement this part, but we only render a small portion of the terrain around the player's current position. More details when I talk about distance fog.

In the `Chunk` class, we store raw pointers to its neighbor chunks for each direction. This way we can check neighbors of blocks that reside in a neighboring chunk.

```cpp
enum Direction {
  X_POS, X_NEG, Z_POS, Z_NEG, Y_POS, Y_NEG
};

class Chunk
{
private:
  std::array<Block, 16 * 16 * 256> blocks;

  // this really only makes sense for the X_POS, X_NEG, Z_POS, and Z_NEG directions
  std::unordered_map<Direction, Chunk*> neighbors;
};
```

If you were to go below ground in debug mode, everything now looks "hollowed out." What you're seeing in the picture below are what our caves look like from the outside! The player is technically inside solid `STONE` right now, it's just not being drawn.

<Img src={import("./hollowed-caves.png")} alt="Since we're not rendering any blocks inside the terrain, we can see snake-like caves underground." />

> Take a look at that GUI. I'm so proud of it. Details later.

**I cannot emphasize how much this improves performance.** On my laptop, my framerate basically tripled. Our game would feel horrible to play without these optimizations.

## Texturing and block animations

I render our chunks using <Link href="https://www.opengl-tutorial.org/intermediate-tutorials/tutorial-9-vbo-indexing/" newTab>indexed rendering</Link> and store all vertex attributes in a single, <Link href="https://www.khronos.org/opengl/wiki/Vertex_Specification#Interleaved_attributes" newTab>interleaved</Link> VBO. This includes UV texture information and a single "animated" flag that I either set to 0 or 1.

```cpp
struct VertexAttrs
{
  glm::vec4 position;
  glm::vec4 normal;
  glm::vec2 uv;
  GLfloat animated;
  /* ...more attributes here */
}

int stride = 4 + 4 + 2 + 1 /* + whatever +  additional + attrs */;
```

When passing vertex data to the GPU via `glVertexAttribPointer`, we utilize this `stride` value to tell the GPU when the data for the next vertex starts. We also specify the length, or the "size" of each attribute. For example, `position` is 4 floats long, while `uv` is only 2 floats.

<Img src={import("./interleaved-vbo.png")} alt="In a stream of floats, we specify the first four to be for position, the next four to be for normals, and so on." />

All the block textures in our game live in a 256x256 texture sprite. Since each block face texture is 16x16 pixels, we can refer to specific textures using a coordinate system.

<Img src={import("./block-uv.png")} alt="A dirt face texture at coordinate (2, 1) corresponds to (2/16, 1/16) in UV coordinates." />

Furthermore, we map a block type to the coordinate of the texture for each of its six faces.

```cpp
std::unordered_map<Block, std::unordered_map<Direction, glm::ivec2>> block_uv_map;

// for example, to access the UV coordinates for the Y_NEG face of a dirt block
glm::ivec uv = block_uv_map[DIRT][Y_NEG];
```

UVs span a relative range of 0.0-1.0 in both dimensions, and block face textures take up 1/16th of the total sprite, so we simply multiply the coordinate by 1/16 to get the correct UV. Note that this only describes the lower-left corner; we simply add 1/16 to either U, V, or both to get the other three corners.

And animation? In this case, this refers to water and lava blocks seemingly "flowing." This effect was achieved by slowly translating over the texture sprite, moving the UV coordinate over time. "Time" in this case is a `uniform` variable in the shader that increments every frame.

### Transparent blocks

To avoid transparent blocks (like water, glass, etc.) incorrectly drawing over opaque blocks, we actually keep two separate VBOs and index buffers: one for opaque blocks and one for transparent.

In `render_terrain()`, for every chunk we first draw all opaque blocks to screen, and then all transparent blocks. This solves our issues.

```cpp
void Terrain::render_terrain() {
  // first render opaque blocks
  for (const Chunk* c : chunk_list) {
    c->render(true);
  }

  // then render transparent blocks
  for (const Chunk* c : chunk_list) {
    c->render(false);
  }
}
```

## Distance fog

If we fly really high up into the air, you'll see this circular fog that surrounds the player and slowly fades blocks into the distance.

<Img src={import("./distance-fog.png")} alt="Blocks slowly fade into the distance in a circular radius around the player." />

In the chunk fragment shader, I pass in the player's world position as a `uniform` and the fragment's world position as an `in` from the vertex shader. I find the distance between these two and divide by the max distance to get a value between 0.0-1.0.

This is used to lerp between the original block color and the sampled sky color. I use a nice <Link href="https://easings.net/#easeInCubic" newTab>cubic easing curve</Link> to make the fog get denser the further the block is from the player.

So, what is this max fog distance? At all times, we only render a specific number of chunks around the player. A 12x12 square of chunks, to be exact. The player is always at the center, so the max distance (which is the circle radius) is at most 96 blocks.

<Img src={import("./distance-fog-diagram.png")} alt="Diagram depicting the fog starting roughly around 96 blocks around the player in all directions." />

Apart from aesthetic purposes, the distance fog takes on a second role: to stop the player from seeing anything past the section of terrain we're drawing around them. But, distance fog is worth it to implement for aesthetics alone, in my opinion.

<Img src={import("./distance-fog-pretty.png")} alt="A beautiful sunrise over the desert." />

## Day/night cycle, celestial objects

Apart from GUI, I am probably most proud of our engine's day and night cycle. We see the sun during the day, and the moon and stars at night. In between, sunrises and sunsets transition us nicely.

<Img src={import("./day-night-cycle.png")} alt="A diagram depicting what percentage of a day we spend in day, in night, and how long it takes to transition." />

During development, I religiously followed the diagram above. It defines a single day as a range from 0.0-1.0, and specifies exact durations for transitions between sections.

- "Day" is considered to be 0-0.375, and is 0.375 long.
- "Sunset" is considered to be 0.375-0.5, and is 0.125 long.
- The transition between Day and Sunset starts at 0.3125 and ends at 0.4375. It is 0.125 long.
- To enable a seamless Sunrise and Day transition, we split it when we go from `1 -> 0`.

Making calculations depend on a relative 0.0-1.0 scale instead of a hardcoded number made changing the day length for debugging infinitely easier.

### Skybox

The skybox was not implemented using a cubemap. Instead, we perform a raycast from a pixel on our screen to the player camera in world position. In other words, we are going from screen space back to world space. The "skybox" is just a quad that we paint funny stuff on.

We choose the far clip of the camera as the point where our ray should end. Since the ray is defined to start from the camera eye, we are essentially drawing a giant sphere around the player, where the ray becomes the radius.

In fact, we can map the calculated ray to a color value. What we get is this:

<Img src={import("./skybox-uv.png")} alt="The sky is split into green, red, and black." />

This makes sense. Our crosshair is currently in the middle of three large color blotches. If we look along the x-axis (to the right), we get lots of red. If we look along the y-axis (up), we get lots of green. If we look behind us, we get black.

### Where are the funny colors coming from??

I think one thing that helped me understand this better was that all of this was being performed by the fragment shader, which has a different `gl_FragCoord` for each pixel on your screen. This means that the raycast to the player camera will return different results, and therefore result in many different colors.

When you rotate your camera and look somewhere else, the world space position of the point you're raycasting to is different as well. That's how we get an illusion of the sky "moving" as we turn, when in reality we're just painting to a rectangle!

### Celestial objects

The sun, moon, and stars are a bit easier to wrap your head around. Both the sun and moon are simply two quads that rotate at a fixed distance around the player. This allows them to appear "infinitely" far away.

In our <Link href="https://doc.qt.io/qt-6/qopenglwidget.html#paintGL" newTab>`paintGL()`</Link>, after drawing the sun and moon and before drawing the terrain, I reset the OpenGL depth buffer. This means that they are *always* drawn behind the terrain, no matter how high or low you are.

```cpp
// this is a built-in Qt function that makes it easier to communicate with OpenGL.
// it is called every time our scene is drawn, so ~60 times a second.
void MyWidget::paintGL() {
  /* rendering stuff */

  sun.render();
  moon.render();

  // reset depth buffer so all celestial objects are drawn behind terrain
  glClear(GL_DEPTH_BUFFER_BIT);

  terrain.render_terrain();
}
```

Each individual star is a tiny quad that I rotate and scale by a random amount. I originally had the stars rotate around the player too, but that looked too unrealistic when the player climbed things. Instead, it only follows the player's x- and z-coordinates, but rotates at a fixed y-height.

### Clouds

A giant quad floats above the player at all times. On it, I sample a portion of a large texture that contains all the possible clouds in the world:

<Img src={import("./clouds-ps.png")} alt="Cloud texture is opened in Photoshop." />

This was created in Photoshop. I used a noise function as the base, reduced the number of colors, and deleted the rest to make somewhat realistic-looking swirlies.

When I send the texture to the GPU, I set these options so that the texture repeats for values of UV outside of 0.0-1.0:

```cpp
// keeps textures nice and pixelated
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);

// repeat clouds
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);
```

This way, I can offset the UV coordinates based on the player's current world position. When the player moves forward, the UV coordinates translate "back," which gives the clouds the appearance of having been left behind. Some fragment shader code:

```glsl
uniform vec3 PlayerPos;
uniform sampler2D Texture;
uniform int Time;

in vec2 UV;

const float CLOUDS_INTERVAL = /* how fast the clouds move */;
const float CLOUDS_SIZE = /* make this bigger than your clouds texture */;

void main() {
  vec2 offset = vec2(mod(PlayerPos.z, CLOUDS_SIZE) / CLOUDS_SIZE, mod(-PlayerPos.x, CLOUDS_SIZE) / CLOUDS_SIZE);
  vec4 texColor = texture(Texture, UV + offset + vec2(mod(Time, CLOUDS_INTERVAL) / CLOUDS_INTERVAL, 0));

  /* do some other stuff like distance fog and then output the color */
}
```

I also use the previously mentioned `uniform` time variable to make the clouds translate across the sky even when you're not moving.

These three components are pretty simple, but with some good skybox colors, animation times, and tweaking, our sky system feels cohesive and full of personality.

## Flood fill lighting

This section could get its own entire write-up, but there are many articles on the internet that do a much better job explaining than I ever could. I'll link some here:

- <Link href="https://www.reddit.com/r/gamedev/comments/2iru8i/fast_flood_fill_lighting_in_a_blocky_voxel_game/" newTab>This Reddit post</Link>
- <Link href="https://0fps.net/2018/02/21/voxel-lighting/" newTab>0 FPS - Voxel lighting</Link>
- <Link href="https://minecraft.wiki/w/Light#Block_light" newTab>Minecraft Wiki</Link>
- <Link href="https://en.wikipedia.org/wiki/Flood_fill" newTab>Wikipedia article about flood fill</Link>

In our engine, I store a 1D array for each chunk that tracks each block's light level. Just like Minecraft, our light scale ranges from 0-15.

```cpp
class Chunk
{
private:
  std::array<Block, 16 * 16 * 256> blocks;
  std::unordered_map<Direction, Chunk*> neighbors;

  // using ints are overkill for our purposes and take up more space
  std::array<unsigned char, 16 * 16 * 256> light_level;
};
```

When we generate block data for a chunk, I keep track of all the naturally occurring light sources in the scene. After we finish, I run the flood fill algorithm on each light source, using a light value of 15. It's important to do this after we populate the `blocks` array so that the algorithm doesn't propagate through opaque blocks.

Remember `VertexAttrs` from earlier? We add a new single-float attribute called `lightLevel`. In our fragment shader, we multiply our default block color by this additional brightness. Make sure to clamp it between 0.0-1.0 so the block doesn't get *too* bright.

> I did the base algorithm implementation, and it works well for "no color" lights. My teammate decided to jazz it up a bit and added colored lights! That's what you see in the video.

Note that each block face samples the light level from the neighbor block it's adjacent to. Depending on the light location, this also means each block face can be affected by a different light value!

## GUI, inventory, text rendering

The inventory system is very simple. Stupidly simple. Here, I'll reimplement it right here:

```cpp
struct Inventory
{
  std::array<Block, 9> slots;
  int active;
};
```

Pressing numkeys 1-9 (or scrolling with mouse wheel) sets the `active` variable accordingly. Whenever we want to access the currently selected block, we index into `slots` using `active`. This is nice because we don't have to keep track of what `Block` is selected, that is abstracted away for us.

The UI took a bit more planning. Every UI element inherits from a base class that stores our screen's width, height, and aspect ratio. UI lives on a 2D surface, and so I use UV-like coordinates to specify each UI element's position on the screen.

For example, if we wanted to draw a crosshair texture on a square at the center of the screen, I could use the following vertex positions:

```cpp
class Crosshair : public UI
{
  void set_vbo_data();
};

void Crosshair::set_vbo_data() {
  // upper right, lower right, lower left, and upper left corners
  pos = {glm::vec2(0.51f, 0.51f),
         glm::vec2(0.51f, 0.49f),
         glm::vec2(0.49f, 0.49f),
         glm::vec2(0.49f, 0.51f)};
}
```

We store the index, position, and UV buffers as `std::vector` member variables in `UI`. The `UI` base class only needs one function: `render_ui()`. It looks something like this:

```cpp
void UI::render_ui() {
  int diff = screen_w - screen_h;
  float margin = diff / 2.f;

  std::vector<glm::vec2> scaled_pos;
  for (const glm::vec2 &p : pos) {
    scaled_pos.push_back(glm::vec2(p.x * screen_w / aspect_ratio + margin, p.y * screen_h));
  }

  /* send all of this correctly scaled vertex data to the GPU */
}
```

We're allowed to define our UI element positions on a relative 0.0-1.0 scale because the `UI` class takes care of transforming it into actual positions based on our current working screen resolution. Furthermore, the x-values are offset by a margin that centers everything.

<Img src={import("./ui-scaling.png")} alt="Diagram showing how the UI is scaled up and doesn't matter what screen resolution we are." />

I make a number of assumptions. First, that the screen width is greater than the height. Also, that the aspect ratio is always greater than 1. In addition, UI elements only exist in a square in the middle of the screen. However, for our rudimentary crosshair, hotbar, and text, this is more than enough to scale well and work across all screen resolutions.

The hotbar naturally uses `UI` as well. To render the currently active slot, I add an additional offset to its x-position depending on what slot number we're on.

### Text rendering

Picture this. It's 4 AM and there are only a few hours left before the due date. Everything else is done but you don't want to sleep yet. You decide to go all out on one last thing, or fall asleep trying. End result? Very, very basic text rendering.

## Conclusion